import { streamText, tool } from 'ai';
import { z } from 'zod';
import { aggressiveWebSearchTool, weatherTool, locationDetectorTool, arxivTool } from '../tools';
import { performExaSearch } from '../exa-service';
import { getModelInfo, isReasoningModel } from './models';
import { customProviderWithTools } from './providers';
import { generateAIText } from './service';
import { ToolCallOptions } from '@/types/ai';

/**
 * Enhanced AI Text Generation with Tool Calling Support
 * 
 * This module provides advanced tool calling capabilities for reasoning models including:
 * - DeepSeek R1 Distill 70B (Groq)
 * - Qwen3 32B (Groq) 
 * - GPT-OSS 120B & 20B (Groq) - Enhanced reasoning models with tool calls
 * - Grok 3 Mini & Grok 4 (XAI)
 * - O4 Mini & GPT-4.1 (OpenAI)
 * - Claude Sonnet 4 (Anthropic)
 * 
 * GPT-OSS models are specifically configured as reasoning models with:
 * - Conservative token management (2 messages, 2048 max tokens)
 * - Reasoning middleware for step-by-step thinking
 * - Enhanced provider options (parallelToolCalls: false, reasoningSummary: detailed)
 * - Aggressive web search with minimal queries for efficiency
 */

// Generate AI response with tool calling for web search
export async function generateAITextWithTools({
  model,
  messages,
  maxTokens = 8192,
  temperature = 0.7,
  webSearchEnabled = false,
  arxivMode = false,
  customInstructions = null,
  latitude = null,
  longitude = null,
}: ToolCallOptions) {
  try {
    console.log(`üîß generateAITextWithTools called:`, {
      model,
      webSearchEnabled,
      messagesCount: messages.length,
      lastMessage: messages[messages.length - 1]?.content,
      isGPTOSS: model.includes('gpt-oss')
    });

    const modelInfo = getModelInfo(model);
    if (!modelInfo) {
      throw new Error(`Model not found: ${model}`);
    }

    console.log(`üìã Model info:`, {
      name: modelInfo.name,
      provider: modelInfo.provider,
      reasoningModel: modelInfo.reasoningModel,
      isGPTOSS: modelInfo.id.includes('gpt-oss'),
      modelType: modelInfo.id.includes('gpt-oss') ? 'GPT-OSS Reasoning Model' : (modelInfo.reasoningModel ? 'Reasoning Model' : 'Standard Model')
    });

    // Skip web search if not enabled
    if (!webSearchEnabled) {
      console.log(`‚ö†Ô∏è Web search not enabled`);
      return await generateAIText({
        model,
        messages,
        maxTokens,
        temperature
      });
    }

    // For models that support tools, use Scira-style tool calling
    if (webSearchEnabled && typeof window === 'undefined' && modelInfo.supportsTools && customProviderWithTools) {
      const modelType = modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Standard';
      console.log(`üöÄ Using websearch tool calling for ${modelType} ${modelInfo.name} (${modelInfo.provider})`);
      
      // Get the user's query from the last user message
      const userQuery = messages.filter(m => m.role === 'user').pop()?.content || '';
      
      if (userQuery.trim()) {
        const modelType = modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Standard';
        console.log(`üîç Aggressive web search enabled for ${modelType} model: ${userQuery}`);
        
        // Enhanced token management for Groq models
        let truncatedMessages = messages;
        let maxTokensForModel = maxTokens;
        let isTokenLimitedModel = false;
        
        if (modelInfo.provider === 'groq') {
          // Check if it's a reasoning model (Deepseek, Qwen, GPT-OSS) vs regular tool-calling model
          const reasoningModels = ['deepseek-r1-distill-llama-70b', 'qwen/qwen3-32b', 'openai/gpt-oss-120b', 'openai/gpt-oss-20b'];
          isTokenLimitedModel = reasoningModels.includes(modelInfo.id);
          
          if (isTokenLimitedModel) {
            // Conservative settings for reasoning models (DeepSeek, Qwen, GPT-OSS) - they need more context
            truncatedMessages = messages.slice(-2); // Keep only last 2 messages
            maxTokensForModel = 2048; // Moderate token limit
            const modelType = modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Reasoning';
            console.log(`üß† Conservative token management for ${modelType} reasoning model ${model}: ${messages.length} ‚Üí ${truncatedMessages.length} messages, maxTokens: ${maxTokensForModel}`);
          } else {
            // Standard settings for regular tool-calling models
            truncatedMessages = messages.slice(-3); // Keep only last 3 messages
            maxTokensForModel = 2048; // Standard token limit
            console.log(`üîß Standard token management for tool-calling model ${model}: ${messages.length} ‚Üí ${truncatedMessages.length} messages, maxTokens: ${maxTokensForModel}`);
          }
        }

        // System instructions based on mode
        const systemInstructions = arxivMode ? `
You are an AI research assistant called Qurse, designed to help users find academic research papers on arXiv and answer their questions using the content from those papers.

CRITICAL INSTRUCTIONS FOR ARXIV MODE:
1. When you use the arxiv_search tool, you MUST analyze the paper abstracts and content
2. You MUST provide a detailed, comprehensive answer using the information from the papers
3. NEVER just say "Response generated successfully" - always provide substantive content
4. If a user asks for detailed explanation of a paper, you MUST extract and explain the key points from that paper's abstract and content
5. Synthesize insights from multiple papers when relevant
6. Provide specific details, methodologies, findings, and conclusions from the papers
7. **CRITICAL FOR GPT-OSS: After completing tool calls, you MUST generate a complete response using the tool results**

RESPONSE REQUIREMENTS:
- Start with a comprehensive answer to the user's question
- Use information from the paper abstracts and content
- Explain key methodologies, findings, and implications
- If explaining a specific paper, break down its contributions, methodology, and results
- End with a list of the key papers that support your answer

NEVER return empty responses or generic messages. Always provide detailed, substantive content based on the research papers found.
` : `
You are an AI web search engine called Qurse, designed to help users find information on the internet with no unnecessary chatter and more focus on the content and respond with markdown format and the response guidelines below.

**CRITICAL INSTRUCTION:**
- ‚ö†Ô∏è URGENT: RUN THE AGGRESSIVE WEB SEARCH TOOL IMMEDIATELY when user sends ANY message - NO EXCEPTIONS
- ‚ö†Ô∏è URGENT: Always respond with markdown format!!
- EVEN IF THE USER QUERY IS AMBIGUOUS OR UNCLEAR, YOU MUST STILL RUN THE WEB SEARCH TOOL IMMEDIATELY
- NEVER ask for clarification before running the tool - run first, clarify later if needed
- If a query is ambiguous, make your best interpretation and run the web search tool right away
- After getting results, you can then address any ambiguity in your response
- DO NOT begin responses with statements like "I'm assuming you're looking for information about X"
- NEVER preface your answer with your interpretation of the user's query
- GO STRAIGHT TO ANSWERING the question after running the web search tool
- **CRITICAL FOR GPT-OSS: After completing tool calls, you MUST generate a complete response using the tool results**

**IMPORTANT: After running the web search tool, you MUST provide a complete, helpful response to the user's question. Do not stop after tool calls - always provide the final answer.**

**Web Search Tool Guidelines:**
- Use the aggressive_web_search tool to find relevant information
- Focus on the most recent and relevant results
- Extract key information from multiple sources
- Provide comprehensive answers based on the search results

**Response Format:**
- Always provide a complete, helpful response after tool execution
- Use markdown formatting for better readability
- Include relevant information from the search results
- Be concise but informative
- At the end, summarize the key findings from the sources

Today's Date: ${new Date().toLocaleDateString('en-US', { year: 'numeric', month: 'short', day: '2-digit', weekday: 'short' })}
${latitude && longitude ? `\nThe user's location is ${latitude}, ${longitude}.` : ''}
${customInstructions ? `\n\nThe user's custom instructions are as follows and YOU MUST FOLLOW THEM AT ALL COSTS: ${customInstructions}` : ''}
`;

        let capturedReasoning: any = null;
        let capturedSources: any[] = [];
        
        try {
          // Check if the model is available in customProviderWithTools
          const modelLanguageModel = customProviderWithTools.languageModel(modelInfo.id);
          if (!modelLanguageModel) {
            console.log(`‚ö†Ô∏è Model ${modelInfo.id} not found in customProviderWithTools, falling back to service approach`);
            throw new Error(`Model ${modelInfo.id} not available for tool calling`);
          }
          
          // Enhanced configuration for reasoning models
          const streamConfig: any = {
            model: modelLanguageModel,
            messages: truncatedMessages,
            maxTokens: maxTokensForModel,
            temperature: temperature,
            maxSteps: modelInfo.reasoningModel ? 5 : 3, // More steps for reasoning models
            maxRetries: 10,
            experimental_activeTools: arxivMode ? ['arxiv_search', 'weather', 'location_detector'] : ['aggressive_web_search', 'weather', 'location_detector'],
            system: systemInstructions,
          };

          // Add provider-specific options for reasoning models
          if (modelInfo.reasoningModel && modelInfo.provider === 'groq') {
            streamConfig.providerOptions = {
              groq: {
                parallelToolCalls: false, // Disable parallel tool calls for reasoning models
                reasoningSummary: 'detailed', // Enable detailed reasoning summary
              }
            };
            console.log(`üß† Enhanced configuration for ${modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Groq'} reasoning model: parallelToolCalls=false, reasoningSummary=detailed`);
          }
          
          // GPT-OSS specific configuration
          if (modelInfo.id.includes('gpt-oss')) {
            streamConfig.maxSteps = 6; // Allow more steps for GPT-OSS to complete responses
            streamConfig.maxRetries = 15; // More retries for GPT-OSS
            console.log(`üö® GPT-OSS specific configuration: maxSteps=6, maxRetries=15`);
          }
          
          const result = await streamText({
            ...streamConfig,
            tools: {
              ...(arxivMode ? {
                arxiv_search: arxivTool
              } : {
                aggressive_web_search: isTokenLimitedModel ? 
                  // Create a more conservative tool for reasoning models (DeepSeek, Qwen, GPT-OSS)
                  tool({
                    description: 'Search the web for current information using Exa AI. Use this tool when you need to find recent news, facts, or updates to answer questions accurately. As a reasoning model, think step-by-step about what information you need, then search efficiently with minimal queries.',
                    parameters: z.object({
                      queries: z.array(z.string().describe('Array of search queries to perform (MAX 2 queries)')),
                      strategy: z.enum(['quick', 'deep', 'breaking', 'expert', 'historical']).default('quick').describe('Search strategy to use (use quick for token-limited models)'),
                      maxResults: z.number().min(1).max(3).default(3).describe('Maximum number of results per query (MAX 3 for token-limited models)'),
                      quality: z.enum(['default', 'best']).default('default').describe('Search quality: default=faster, best=better quality'),
                      topic: z.enum(['general', 'news', 'finance']).default('general').describe('Topic type: general, news, or finance'),
                      timePeriod: z.enum(['1h', '1d', '1w', '1m', 'recent']).optional().describe('Time period for results (legacy parameter, mapped to topic)'),
                      maxQueries: z.number().min(1).max(2).default(1).describe('Maximum number of queries to execute (MAX 2 for token-limited models)'),
                    }),
                    execute: async ({ queries, strategy, maxResults, quality, topic, timePeriod, maxQueries }) => {
                      // Force moderate limits for token-limited models
                      const limitedQueries = queries.slice(0, Math.min(maxQueries, 2));
                      const limitedResults = Math.min(maxResults, 3);
                      
                      const modelType = modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Reasoning';
                      console.log(`üö® Conservative Exa search for ${modelType} reasoning model: strategy="${strategy}", maxResults=${limitedResults}, quality="${quality}", topic="${topic}", queries=${limitedQueries.length}`);
                      
                      // Map timePeriod to topic if provided (backward compatibility)
                      let effectiveTopic = topic;
                      if (timePeriod) {
                        if (timePeriod === 'recent' || timePeriod === '1h' || timePeriod === '1d') {
                          effectiveTopic = 'news';
                        } else if (timePeriod === '1w' || timePeriod === '1m') {
                          effectiveTopic = 'general';
                        }
                      }
                      
                      const allResults: any[] = [];
                      
                      for (const query of limitedQueries) {
                        try {
                          const modelType = modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Reasoning';
                          console.log(`üîç Conservative Exa searching with ${modelType} model: ${query}`);
                          const searchResponse = await performExaSearch(query, limitedResults, effectiveTopic, quality);
                          
                          if (searchResponse.results && searchResponse.results.length > 0) {
                            const formattedResults = searchResponse.results.map((result: any, index) => ({
                              query,
                              source: `${index + 1}`,
                              title: result.title,
                              url: result.url,
                              content: result.content,
                              author: result.author,
                              published_date: result.published_date,
                              image: result.image
                            }));
                            
                            allResults.push(...formattedResults);
                          }
                        } catch (error) {
                          console.error(`Conservative Exa search failed for "${query}":`, error);
                        }
                      }
                      
                      // Store the results globally so we can access them later
                      console.log('üîç Storing search results globally:', allResults);
                      (global as any).lastSearchResults = allResults;
                      
                      return {
                        totalQueries: limitedQueries.length,
                        totalResults: allResults.length,
                        strategy: strategy,
                        maxResults: limitedResults,
                        quality: quality,
                        topic: effectiveTopic,
                        timePeriod: timePeriod,
                        results: allResults,
                        summary: `Conservative search with ${modelInfo.id.includes('gpt-oss') ? 'GPT-OSS' : 'Reasoning'} model: ${strategy} strategy, ${limitedResults} results/query, ${quality} quality, ${effectiveTopic} topic, ${limitedQueries.length} queries. Found ${allResults.length} total results.`
                      };
                    },
                  }) : aggressiveWebSearchTool
              }),
              weather: weatherTool,
              location_detector: locationDetectorTool,
            },
            onChunk(event) {
              if (event.chunk.type === 'tool-call') {
                console.log('Called Tool: ', event.chunk.toolName);
              }
            },
            onStepFinish(event) {
              if (event.warnings) {
                console.log('Warnings: ', event.warnings);
              }
            },
            onFinish: async (event) => {
              console.log('Fin reason: ', event.finishReason);
              console.log('Reasoning: ', event.reasoning);
              console.log('Steps: ', event.steps);
              console.log('Messages: ', event.response.messages);
              console.log('Response Body: ', event.response.body);
              console.log('Provider metadata: ', event.providerMetadata);
              console.log('Sources: ', event.sources);
              console.log('Usage: ', event.usage);
              
              // Capture reasoning data from steps and event.reasoning
              const allReasoning = [];
              
              // Get reasoning from event.reasoning first (if available)
              if (event.reasoning && typeof event.reasoning === 'string' && event.reasoning.trim()) {
                allReasoning.push(event.reasoning.trim());
              }
              
              // Get reasoning from steps
              if (event.steps && event.steps.length > 0) {
                event.steps.forEach((step, index) => {
                  if (step.reasoning && typeof step.reasoning === 'string' && step.reasoning.trim()) {
                    const stepReasoning = step.reasoning.trim();
                    // Only add if it's not just "**Answer**" or similar short non-reasoning content
                    if (stepReasoning.length > 20 && !stepReasoning.match(/^\*\*[A-Za-z]+\*\*$/)) {
                      allReasoning.push(`Step ${index + 1}:\n${stepReasoning}`);
                    }
                  }
                });
              }
              
              if (allReasoning.length > 0) {
                capturedReasoning = {
                  step1Reasoning: event.steps?.[0]?.reasoning || '',
                  step2Reasoning: event.steps?.[1]?.reasoning || '',
                  combinedReasoning: allReasoning.join('\n\n---\n\n')
                };
                console.log('üß† Captured reasoning data:', {
                  totalSteps: allReasoning.length,
                  reasoningLength: capturedReasoning.combinedReasoning.length
                });
              }
              
              // First, try to get sources from globally stored search results
              if ((global as any).lastSearchResults && (global as any).lastSearchResults.length > 0) {
                console.log('üîç Found globally stored search results:', (global as any).lastSearchResults);
                
                // Check if this is arXiv mode based on the first result
                const isArxivResults = (global as any).lastSearchResults[0]?.arxiv_id || 
                                     (global as any).lastSearchResults[0]?.url?.includes('arxiv.org');
                
                if (isArxivResults) {
                  // Preserve arXiv-specific metadata for arXiv results
                  capturedSources = (global as any).lastSearchResults.map((result: any, index: number) => ({
                    title: result.title,
                    relevance_score: result.relevance_score || (1 - (index * 0.1)),
                    domain: 'arxiv.org',
                    url: result.url,
                    favicon: '/icon/arxiv-logo.svg',
                    // Preserve arXiv-specific fields
                    arxiv_id: result.arxiv_id,
                    authors: result.author || result.authors,
                    abstract: result.content || result.abstract,
                    submission_date: result.published_date || result.submission_date,
                    pdf_url: result.pdf_url
                  }));
                } else {
                  // Standard web search results
                  capturedSources = (global as any).lastSearchResults.map((result: any, index: number) => ({
                    title: result.title,
                    relevance_score: 1 - (index * 0.1), // Higher position = higher relevance
                    domain: new URL(result.url).hostname.replace('www.', ''),
                    url: result.url,
                    favicon: `https://www.google.com/s2/favicons?domain=${result.url}&sz=32`
                  }));
                }
                
                console.log('‚úÖ Captured sources from global search results:', capturedSources);
                // Clear the global storage after use
                (global as any).lastSearchResults = null;
              }
              // Fallback: Capture sources from event.sources if available
              else if (event.sources && event.sources.length > 0) {
                console.log('üîç Found event.sources:', event.sources);
                capturedSources = event.sources.map((source: any, index: number) => ({
                  title: source.title || source.content || 'Unknown Title',
                  relevance_score: 1 - (index * 0.1), // Higher position = higher relevance
                  domain: source.url ? new URL(source.url).hostname.replace('www.', '') : 'unknown',
                  url: source.url || '#',
                  favicon: source.url ? `https://www.google.com/s2/favicons?domain=${source.url}&sz=32` : undefined
                }));
                console.log('‚úÖ Captured sources from event.sources:', capturedSources);
              }
              
              // Also check if there are search results in the response body
              if (capturedSources.length === 0 && event.response?.body) {
                console.log('üîç Checking response body for search results:', event.response.body);
                // The search results might be embedded in the response body
                try {
                  const bodyData = event.response.body as any;
                  if (bodyData && typeof bodyData === 'object') {
                    // Look for results in various possible locations
                    const possibleResults = bodyData.results || bodyData.data || bodyData.searchResults || bodyData.webSearchResults;
                    if (possibleResults && Array.isArray(possibleResults) && possibleResults.length > 0) {
                      console.log('üîç Found search results in response body:', possibleResults);
                      capturedSources = possibleResults.map((result: any, index: number) => ({
                        title: result.title || result.content || 'Unknown Title',
                        relevance_score: 1 - (index * 0.1), // Higher position = higher relevance
                        domain: result.url ? new URL(result.url).hostname.replace('www.', '') : 'unknown',
                        url: result.url || '#',
                        favicon: result.url ? `https://www.google.com/s2/favicons?domain=${result.url}&sz=32` : undefined
                      }));
                      console.log('‚úÖ Captured sources from response body:', capturedSources);
                    }
                  }
                } catch (error) {
                  console.error('Error parsing response body for sources:', error);
                }
              }
            },
          });

          // Extract the final response content
          let finalContent = '';
          
          // First try to get content from the text stream
          for await (const chunk of result.textStream) {
            finalContent += chunk;
          }
          
          console.log(`üîç Text stream content length: ${finalContent.length}, contains tool calls: ${finalContent.includes('<tool_use>') || finalContent.includes('tool_calls')}`);
          
          // If text stream is empty or only contains tool calls, get the final response from the result
          if (!finalContent || finalContent.trim().length === 0 || finalContent.includes('<tool_use>') || finalContent.includes('tool_calls')) {
            console.log(`üîç Text stream empty or contains tool calls, extracting final response from result...`);
            
            // Get the final assistant message from the response
            const response = await result.response;
            console.log(`üîç Response object:`, response ? 'exists' : 'null');
            
            const finalMessages = response?.messages || [];
            console.log(`üîç Final messages count: ${finalMessages.length}`);
            
            const assistantMessages = finalMessages.filter((msg: any) => msg.role === 'assistant');
            console.log(`üîç Assistant messages count: ${assistantMessages.length}`);
            
            const lastAssistantMessage = assistantMessages.pop();
            console.log(`üîç Last assistant message:`, lastAssistantMessage ? 'exists' : 'null');
            
            if (lastAssistantMessage?.content) {
              console.log(`üîç Last assistant message content type:`, typeof lastAssistantMessage.content);
              
              // Handle different content types
              if (typeof lastAssistantMessage.content === 'string') {
                finalContent = lastAssistantMessage.content;
                console.log(`‚úÖ Extracted string content: ${finalContent.substring(0, 100)}...`);
              } else if (Array.isArray(lastAssistantMessage.content)) {
                // Extract text from content parts
                const textParts = lastAssistantMessage.content
                  .filter((part: any) => part.type === 'text')
                  .map((part: any) => part.text)
                  .join('');
                finalContent = textParts;
                console.log(`‚úÖ Extracted array content: ${finalContent.substring(0, 100)}...`);
              } else {
                console.log(`‚ö†Ô∏è Unknown content type, using fallback`);
                finalContent = 'I have processed your request and gathered the information you needed.';
              }
            } else {
              console.log(`‚ö†Ô∏è No assistant message content found, checking for text property`);
              
              // Try alternative extraction methods
              try {
                const fullText = await result.text;
                if (fullText && fullText.trim().length > 0) {
                  finalContent = fullText;
                  console.log(`‚úÖ Extracted from result.text: ${finalContent.substring(0, 100)}...`);
                } else {
                  console.log(`‚ö†Ô∏è No content found anywhere, using fallback`);
                  finalContent = arxivMode 
                    ? 'I found relevant research papers for your query. Please check the sources for detailed information.'
                    : 'I have processed your request and gathered the information you needed.';
                }
              } catch (textError) {
                console.log(`‚ö†Ô∏è Error extracting text, using fallback:`, textError);
                finalContent = arxivMode 
                  ? 'I found relevant research papers for your query. Please check the sources for detailed information.'
                  : 'I have processed your request and gathered the information you needed.';
              }
            }
          }

          // GPT-OSS specific fix: If content is still empty but we have tool results and reasoning, generate a response
          if ((!finalContent || finalContent.trim().length === 0) && 
              modelInfo.id.includes('gpt-oss') && 
              capturedSources.length > 0 && 
              capturedReasoning) {
            console.log(`üö® GPT-OSS specific fix: Generating response from tool results and reasoning`);
            
            if (arxivMode) {
              // Generate a comprehensive response based on the captured sources and reasoning
              const papers = capturedSources;
              const mostRecentPaper = papers[0]; // Highest relevance score
              
              finalContent = `## Latest Cryptocurrency Research Papers

Based on my search of arXiv, I found several relevant research papers on cryptocurrency. Here are the key findings:

### Most Recent Research: ${mostRecentPaper.title}
- **arXiv ID:** ${mostRecentPaper.arxiv_id}
- **Focus:** ${mostRecentPaper.abstract.substring(0, 200)}...
- **Categories:** ${mostRecentPaper.categories || 'Cryptography and Security'}

### Additional Research Papers:
${papers.slice(1).map((paper, index) => `
**${index + 2}. ${paper.title}**
- arXiv ID: ${paper.arxiv_id}
- Abstract: ${paper.abstract.substring(0, 150)}...
- PDF: [View Paper](${paper.pdf_url})
`).join('\n')}

### Key Insights:
The research shows ongoing work in cryptocurrency regulation, blockchain technology applications, and the intersection of blockchain with artificial intelligence. The papers cover topics from regulatory frameworks to technical implementations and societal impacts.

*All papers are available through the sources below with full abstracts and PDF access.*`;
            } else {
              // For web search mode, generate a response based on the search results
              const results = capturedSources;
              finalContent = `## Search Results Summary

I found ${results.length} relevant sources for your query:

${results.map((result, index) => `
**${index + 1}. ${result.title}**
- Source: ${result.domain}
- Summary: ${result.content ? result.content.substring(0, 150) + '...' : 'Content available at source'}
- [Read More](${result.url})
`).join('\n')}

*All sources are available below for detailed information.*`;
            }
            
            console.log(`‚úÖ GPT-OSS response generated: ${finalContent.substring(0, 100)}...`);
          }

          console.log(`üîç Model completed tool calls. Final content: ${finalContent.substring(0, 100)}...`);
          
          console.log(`üîç Returning AI response with sources:`, {
            hasSources: capturedSources.length > 0,
            sourcesCount: capturedSources.length,
            sources: capturedSources
          });
          
          // Final fallback check - if content is still empty, provide a more helpful message
          if (!finalContent || finalContent.trim().length === 0) {
            finalContent = arxivMode 
              ? 'I searched for relevant research papers but encountered an issue extracting the detailed response. Please try rephrasing your question or check the sources below for the paper information.'
              : 'I processed your request but encountered an issue generating the response content. Please try again.';
          }

          return {
            content: finalContent,
            model: model,
            reasoning: capturedReasoning,
            sources: capturedSources,
            usage: {
              promptTokens: 0,
              completionTokens: 0,
              totalTokens: 0
            }
          };

        } catch (error) {
          console.error('Tool calling failed:', error);
          
          // Fallback to regular generation but preserve sources if we have them
          const fallbackResult = await generateAIText({
            model,
            messages,
            maxTokens: maxTokensForModel,
            temperature
          });
          
          // Return with sources if we captured any
          return {
            ...fallbackResult,
            sources: capturedSources
          };
        }
      }
    }

    // Handle web search for models that support tools but aren't in customProviderWithTools
    if (webSearchEnabled && typeof window === 'undefined' && modelInfo.supportsTools && !customProviderWithTools?.languageModel(modelInfo.id)) {
      console.log(`üîç Model ${modelInfo.name} supports tools but not in customProviderWithTools, using service approach`);
      
      // Get the user's query from the last user message
      const userQuery = messages.filter(m => m.role === 'user').pop()?.content || '';
      
      if (userQuery.trim()) {
        try {
          // Import the Exa service functions
          const { performExaSearch, formatExaSearchResultsForAI } = await import('../exa-service');
          
          // Initialize sources for this section
          let sectionSources: any[] = [];
          
          // Perform web search
          console.log(`üîç Performing Exa search for: ${userQuery}`);
          const searchResponse = await performExaSearch(userQuery, 5, 'general', 'default');
          
          // Capture sources data
          if (searchResponse.results && searchResponse.results.length > 0) {
            sectionSources = searchResponse.results.map((result, index) => ({
              title: result.title,
              relevance_score: 1 - (index * 0.1), // Higher position = higher relevance
              domain: new URL(result.url).hostname.replace('www.', ''),
              url: result.url,
              favicon: `https://www.google.com/s2/favicons?domain=${result.url}&sz=32`
            }));
          }
          
          // Format search results for AI
          const formattedResults = formatExaSearchResultsForAI(searchResponse, false);
          
          // Create enhanced messages with search results
          const enhancedMessages = [
            ...messages.slice(0, -1), // Keep all messages except the last user message
            {
              role: 'user' as const,
              content: `${userQuery}\n\n${formattedResults}`
            }
          ];
          
          console.log(`üìù Enhanced user message with search results for tool-supporting model not in customProviderWithTools`);
          
          // Call the regular AI generation with enhanced messages
          const result = await generateAIText({
            model,
            messages: enhancedMessages,
            maxTokens,
            temperature
          });
          
          console.log(`üîç Service approach returning with sources:`, {
            hasSources: sectionSources.length > 0,
            sourcesCount: sectionSources.length,
            sources: sectionSources
          });
          
          // Return result with sources data
          return {
            ...result,
            sources: sectionSources
          };
          
        } catch (error) {
          console.error('Web search failed for tool-supporting model:', error);
          // Fall back to regular generation without web search
          return await generateAIText({
            model,
            messages,
            maxTokens,
            temperature
          });
        }
      }
    }

    // Handle web search for models that don't support tools (service approach)
    if (webSearchEnabled && !modelInfo.supportsTools) {
      console.log(`üîç Using service approach for model without tool support: ${modelInfo.name}`);
      
      // Get the user's query from the last user message
      const userQuery = messages.filter(m => m.role === 'user').pop()?.content || '';
      
      if (userQuery.trim()) {
        try {
          // Import the Exa service functions
          const { performExaSearch, formatExaSearchResultsForAI } = await import('../exa-service');
          
          // Initialize sources for this section
          let sectionSources2: any[] = [];
          
          // Perform web search
          console.log(`üîç Performing Exa search for: ${userQuery}`);
          const searchResponse = await performExaSearch(userQuery, 5, 'general', 'default');
          
          // Capture sources data
          if (searchResponse.results && searchResponse.results.length > 0) {
            sectionSources2 = searchResponse.results.map((result, index) => ({
              title: result.title,
              relevance_score: 1 - (index * 0.1), // Higher position = higher relevance
              domain: new URL(result.url).hostname.replace('www.', ''),
              url: result.url,
              favicon: `https://www.google.com/s2/favicons?domain=${result.url}&sz=32`
            }));
          }
          
          // Format search results for AI
          const formattedResults = formatExaSearchResultsForAI(searchResponse, false);
          
          // Create enhanced messages with search results
          const enhancedMessages = [
            ...messages.slice(0, -1), // Keep all messages except the last user message
            {
              role: 'user' as const,
              content: `${userQuery}\n\n${formattedResults}`
            }
          ];
          
          console.log(`üìù Enhanced user message with search results for model without tool support`);
          
          // Call the regular AI generation with enhanced messages
          const result = await generateAIText({
            model,
            messages: enhancedMessages,
            maxTokens,
            temperature
          });
          
          console.log(`üîç Service approach 2 returning with sources:`, {
            hasSources: sectionSources2.length > 0,
            sourcesCount: sectionSources2.length,
            sources: sectionSources2
          });
          
          // Return result with sources data
          return {
            ...result,
            sources: sectionSources2
          };
          
        } catch (error) {
          console.error('Web search failed for model without tool support:', error);
          // Fall back to regular generation without web search
          return await generateAIText({
            model,
            messages,
            maxTokens,
            temperature
          });
        }
      }
    }

    // Fallback for other cases
    console.log(`‚ö†Ô∏è Falling back to regular generation - conditions not met for tool calling`);
    return await generateAIText({
      model,
      messages,
      maxTokens,
      temperature
    });

  } catch (error) {
    console.error('AI generation with tools error:', error);
    throw error;
  }
} 